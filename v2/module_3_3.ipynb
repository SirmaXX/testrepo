{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "tensor([ 0, 61,  1, 61,  2, 61,  0, 61,  3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/home/deniz/Masaüstü/llmdersi')  # v2'nin bir üst dizini\n",
    "\n",
    "from v2.usta_model import UstaModel\n",
    "from v2.usta_tokenizer import UstaTokenizer\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = \"mps\"\n",
    "  \n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "u_tokenizer = UstaTokenizer(\"newtokenizer.json\")\n",
    "\n",
    "prompts = [\n",
    "  \"the capital of the united\",\n",
    "  \"madrid is in\",\n",
    "  \"the capital of france is\",\n",
    "  \"the capital of germany is\"\n",
    "]\n",
    "\n",
    "tokens = u_tokenizer.encode(prompts[0])\n",
    "tokens = tokens.to(device)\n",
    "print(tokens)\n",
    "batch_tokens = u_tokenizer.encode_batch(prompts, 32)\n",
    "batch_tokens = batch_tokens.to(device)\n",
    "batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UstaModel:\n\tUnexpected key(s) in state_dict: \"layers.0.self_attention.mask\", \"layers.1.self_attention.mask\", \"layers.2.self_attention.mask\", \"layers.3.self_attention.mask\", \"layers.4.self_attention.mask\", \"layers.5.self_attention.mask\", \"layers.6.self_attention.mask\", \"layers.7.self_attention.mask\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m u_model \u001b[38;5;241m=\u001b[39m UstaModel(\n\u001b[1;32m      5\u001b[0m   vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(u_tokenizer\u001b[38;5;241m.\u001b[39mvocab),\n\u001b[1;32m      6\u001b[0m   embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m   device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mu_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./u_model_4000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UstaModel:\n\tUnexpected key(s) in state_dict: \"layers.0.self_attention.mask\", \"layers.1.self_attention.mask\", \"layers.2.self_attention.mask\", \"layers.3.self_attention.mask\", \"layers.4.self_attention.mask\", \"layers.5.self_attention.mask\", \"layers.6.self_attention.mask\", \"layers.7.self_attention.mask\". "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "context_length = 32\n",
    "\n",
    "u_model = UstaModel(\n",
    "  vocab_size=len(u_tokenizer.vocab),\n",
    "  embedding_dim=12,\n",
    "  num_heads=4,\n",
    "  context_length=context_length,\n",
    "  num_layers=8,\n",
    "  device=device\n",
    ")\n",
    "\n",
    "# load model\n",
    "u_model.load_state_dict(torch.load(\"./u_model_4000.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = u_model(batch_tokens)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature\n",
    "# top_k \n",
    "# top_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([17.5470, 13.6248,  9.1306,  8.0484,  7.2238,  7.1877,  7.1396,  6.7132,\n",
       "          6.3709,  6.3608]),\n",
       " [61, 60, 35, 58, 38, 18, 9, 59, 11, 49])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_outs = sorted(out[-1][-1].tolist(), reverse=True)\n",
    "sorted_indexes = []\n",
    "for so in sorted_outs[:top_k]:\n",
    "  so_index = out[-1][-1].tolist().index(so)\n",
    "  sorted_indexes.append(so_index)\n",
    "sorted_outs = torch.tensor(sorted_outs[:top_k])\n",
    "sorted_outs, sorted_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([17.5470, 13.6248,  9.1306,  8.0484,  7.2238,  7.1877,  7.1396,  6.7132,\n",
       "          6.3709,  6.3608], grad_fn=<TopkBackward0>),\n",
       " tensor([61, 60, 35, 58, 38, 18,  9, 59, 11, 49]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indexes = torch.topk(out[-1][-1], k=10)\n",
    "values, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_296457/2885985782.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adjusted_outs = torch.tensor(sorted_outs) / temperature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.6695, 1.2964, 0.8688, 0.7658, 0.6873, 0.6839, 0.6793, 0.6387, 0.6062,\n",
       "        0.6052])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 10.51\n",
    "adjusted_outs = torch.tensor(sorted_outs) / temperature\n",
    "adjusted_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2124, 0.1462, 0.0953, 0.0860, 0.0795, 0.0793, 0.0789, 0.0758, 0.0733,\n",
       "        0.0733])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(adjusted_outs, dim=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5453)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.2128, 0.36, 0.37, 0.38, 0.70, 0.71]\n",
    "torch.sum(torch.tensor([0.2128, 0.1509, 0.0932, 0.0884]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 93, 8: 71, 0: 219, 6: 89, 7: 78, 1: 140, 4: 87, 3: 80, 9: 63, 5: 80}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_count = {}\n",
    "for _ in range(1000):\n",
    "  sample = torch.multinomial(probs, 1)\n",
    "  sample_count[sample.item()] = sample_count.get(sample.item(), 0) + 1\n",
    "sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the capital of the united europe '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = u_model.generate(tokens,max_new_tokens=3,temperature=0.00000051)\n",
    "u_tokenizer.decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the capital of the united and ': 1,\n",
       " 'the capital of the united.': 3,\n",
       " 'the capital of the united own.': 1,\n",
       " 'the capital of the united the ': 18,\n",
       " 'the capital of the united europe ': 24,\n",
       " 'the capital of the united capitals': 4,\n",
       " 'the capital of the united its ': 2,\n",
       " 'the capital of the united country ': 8,\n",
       " 'the capital of the united a ': 1,\n",
       " 'the capital of the united identitys': 2,\n",
       " 'the capital of the united is ': 4,\n",
       " 'the capital of the united place ': 2,\n",
       " 'the capital of the united spain,': 2,\n",
       " 'the capital of the united capital,': 3,\n",
       " 'the capital of the united states': 1,\n",
       " 'the capital of the united united ': 5,\n",
       " 'the capital of the united capital ': 4,\n",
       " 'the capital of the united has ': 1,\n",
       " 'the capital of the united europe.': 2,\n",
       " 'the capital of the united isberlin': 1,\n",
       " 'the capital of the united city,': 1,\n",
       " 'the capital of the united madrid ': 1,\n",
       " 'the capital of the united europe,': 1,\n",
       " 'the capital of the united together ': 1,\n",
       " 'the capital of the united,, ': 1,\n",
       " 'the capital of the united  europe': 1,\n",
       " 'the capital of the united italy ': 1,\n",
       " 'the capital of the united place.': 2,\n",
       " 'the capital of the united european ': 1,\n",
       " 'the capital of the united, country': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = {}\n",
    "for _ in range(100):\n",
    "  out = u_model.generate(tokens, max_new_tokens = 3, temperature = 1.7, top_k = 10, top_p = 0.7)\n",
    "  decoded = u_tokenizer.decode(out)\n",
    "  outs[decoded] = outs.get(decoded, 0) + 1\n",
    "outs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
